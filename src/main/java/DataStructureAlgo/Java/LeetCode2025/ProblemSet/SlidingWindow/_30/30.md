# Find Substring with Concatenation of All Words

## üß† Intuition

This problem is a variation of the sliding window and substring matching problem, an extension of [76.md](../_76/76.md). The goal is to find all starting indices in the string `s` where a concatenation of all the words in the array `words` (in any order, with no intervening characters) appears exactly once.

Unlike typical character-based window problems (e.g., Leetcode 76: Minimum Window Substring), here we work with fixed-size **words** instead of **characters**. Each window in `s` that we consider will be of size `words.length * wordLen`.

To solve this:
- We count the frequency of each word in `words`.
- For each possible starting index, we check if the substring of length `words.length * wordLen` is a valid concatenation of all words using a helper function.

---

## üßæ Algorithm

1. **Initialize Parameters**:
    - `sLen = s.length()`
    - `wordsLen = words.length`
    - `wordLen = words[0].length()`

2. **Build Word Frequency Map**:
    - Use a hashmap to store frequency of each word in `words`.

3. **Iterate Through Valid Start Indices**:
    - The maximum valid start index is `sLen - wordsLen * wordLen`.
    - For each index `i`, extract the substring of length `wordsLen * wordLen`.
    - Check if it's a valid concatenation using `isValid(...)`.

4. **Validate Substring**:
    - In `isValid(...)`:
        - Split the substring into words of length `wordLen`.
        - Count the frequency of each word and compare with the target word frequency map.

5. **Return All Valid Indices**.

---

## üìä Time and Space Complexity Analysis

Let:
- `n` = length of input string `s`
- `w` = number of words in the array `words`
- `wl` = length of each word in `words` (all words are the same length)

### ‚è± Time Complexity

**1. Building the word frequency map (`wordsMap`)**
- We process each word once and update the map:  
  ‚û§ **O(w)**

**2. Iterating over valid starting indices in `s`**
- Number of iterations: `n - w * wl + 1`  
  ‚û§ **O(n)** in worst case (when `w * wl << n`)

**3. For each iteration:**
- Substring extraction of length `w * wl`:  
  ‚û§ **O(w * wl)**
- Splitting the substring into `w` words of length `wl` and building a frequency map:  
  ‚û§ **O(w * wl)**
- Comparing two maps (`hasFind.equals(wordsMap)`):  
  ‚û§ **O(w)**

**Total per iteration: O(w * wl + w) = O(w * wl)**

**Total Time Complexity:**
```
O(n * w * wl)
```

---

### üß† Space Complexity

- `wordsMap`: stores up to `w` unique words  
  ‚û§ **O(w)**
- `hasFind`: stores frequencies of up to `w` words for each iteration  
  ‚û§ **O(w)**
- Temporary substring of size `w * wl` per iteration  
  ‚û§ **O(w * wl)** but this is reused and not stored permanently

**Total Space Complexity:**
```
O(w)
```




# Optimizations

## üß† Intuition

This problem is a variation of the sliding window approach, where instead of looking for individual characters (as in "Minimum Window Substring"), we look for **fixed-length words** in the input string.

We treat the input string `s` as a stream of `wordLen`-sized chunks and slide a window of size `wordsLen * wordLen` across it. For each window, we check if all words from the list appear **exactly once** in any order.

---

## üßÆ Algorithm

1. **Preprocessing**:
    - Count the frequency of each word in `words` using a `HashMap<String, Integer>`.
    - Let:
        - `wordLen = length of each word` (all are the same),
        - `windowLength = wordLen * words.length`.

2. **Sliding Window Setup**:
    - Start `wordLen` independent windows (to cover all possible alignments).
    - For each window, scan the string in `wordLen`-sized steps.
    - Use a second map `hasFind` to track frequency of words in the current window.

3. **Window Adjustment**:
    - If the current word is part of `words`:
        - Add it to `hasFind`.
        - If it appears more than expected, move the window's start to the right, removing words until frequencies match.
        - If the window is exactly `windowLength` long, store the start index.
    - If it‚Äôs not in `words`, reset the window and clear the map.

4. **Return Result**.

---

## üìä Time and Space Complexity Analysis

Let:
- `n` = length of input string `s`
- `w` = number of words in `words`
- `wl` = length of each word in `words`

### ‚è± Time Complexity

**1. Building `wordsMap` (frequency map):**
```aiignore
O(w)
```

**2. Loop over `wordLen` starting indices:**
- Up to `wordLen` independent loops  
  ‚û§ **O(wl)**

**3. For each loop:**
- Sliding window over the string in steps of `wordLen`  
  ‚û§ **O(n)** total across all loops

**4. Within each step:**
- Substring extraction:  
  ‚û§ **O(wl)**
- Map operations (add/remove/compare):  
  ‚û§ **O(1)** per word (due to bounded word size)

**Total Time Complexity:**
```aiignore
O(n * wl)
```

---

### üß† Space Complexity

- `wordsMap` and `hasFind` store up to `w` unique words  
  ‚û§ **O(w)**

**Total Space Complexity:**
```aiignore
O(w)
```


---

## ‚úÖ Conclusion

This optimized approach leverages:
- Fixed window size,
- Controlled movement using `wordLen`,
- Efficient frequency map comparison,
  leading to a time-efficient solution for large inputs.
